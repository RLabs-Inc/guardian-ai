# GuardianAI Environment Variables

# LLM Service Configuration
# Required for Anthropic Claude models
ANTHROPIC_API_KEY=your_anthropic_api_key_here
# Required for OpenAI models and embeddings
OPENAI_API_KEY=your_openai_api_key_here

# LLM Model Configuration
# MODEL=claude-3-7-sonnet-latest  # For Anthropic
# OPENAI_MODEL=gpt-4o  # For OpenAI
# EMBEDDING_MODEL=text-embedding-3-small  # For OpenAI embeddings
# TEMPERATURE=0.7
# MAX_TOKENS=1000

# RAG Service Configuration
# VECTOR_DIMENSION=1536  # Default for OpenAI text-embedding-3-small
# MIN_SIMILARITY_SCORE=0.7  # Minimum similarity score for RAG results
# MAX_CONTEXT_RESULTS=10  # Maximum number of context results to return
# CONTEXT_WINDOW_SIZE=4000  # Maximum tokens to include in context window
# USE_OPENAI_EMBEDDINGS=true  # Whether to use OpenAI for embeddings

# Agent Service Configuration
# STEWARD_TEMPERATURE=0.2  # Lower temperature for more predictable Steward output
# IMPLEMENTER_TEMPERATURE=0.3  # Slightly higher temperature for more creative Implementation
# AUTO_APPLY_CHANGES=false  # Set to true to automatically apply code changes
# STEWARD_MODEL=claude-3-7-sonnet-latest  # Optional override for Steward agent
# IMPLEMENTER_MODEL=claude-3-7-sonnet-latest  # Optional override for Implementer agent

# File System Configuration
PROJECT_ROOT=/path/to/your/project
# EXCLUDE_PATTERNS=node_modules,dist,.git,build
# INCLUDE_EXTENSIONS=.js,.ts,.py,.go,.java,.jsx,.tsx

# Indexing Configuration
# MAX_FILES_TO_INDEX=1000
# INDEX_CACHE_DIR=.guardian-ai

# Logging Configuration
LOG_LEVEL=info  # debug, info, warn, error